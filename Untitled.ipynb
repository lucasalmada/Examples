{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Publicacoes.csv', encoding='utf-16', sep=\"\\t\", nrows=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df[['Status classificação', 'Conteúdo']])\n",
    "df1.columns = ['status', 'Conteúdo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1[df1['Conteúdo']!= '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    # Retira pontuações e Descapitaliza as palavras\n",
    "    nopunc = [char.lower() for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Junta-os para formar strings\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Remove as stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('portuguese')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Classificado\n",
       "2    Classificado\n",
       "4    Classificado\n",
       "6    Classificado\n",
       "7    Classificado\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['status'] == 'Classificado']['status'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample', 'message', 'notice', 'it', 'has', 'punctuation']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_process('Sample message! Notice: it has punctuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['tamanho_texto'] = df['Conteúdo'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>Conteúdo</th>\n",
       "      <th>tamanho_texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classificado</td>\n",
       "      <td>Compartilhar no Facebook\\nTweet\\nO Programa Ca...</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classificado</td>\n",
       "      <td>Eduardo Anizelli/Folhapress\\nAlém dos postos d...</td>\n",
       "      <td>4435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lixo</td>\n",
       "      <td>Cerca de 300 moradores e comerciantes da regiã...</td>\n",
       "      <td>6751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Classificado</td>\n",
       "      <td>TEUS OLHOS NOS ACONTECIMENTOS \\nr \\n \\nMinas G...</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lixo</td>\n",
       "      <td>HOME › MULTIMIDIA › PODCASTS › Teatro Municipa...</td>\n",
       "      <td>9831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         status                                           Conteúdo  \\\n",
       "0  Classificado  Compartilhar no Facebook\\nTweet\\nO Programa Ca...   \n",
       "2  Classificado  Eduardo Anizelli/Folhapress\\nAlém dos postos d...   \n",
       "3          Lixo  Cerca de 300 moradores e comerciantes da regiã...   \n",
       "4  Classificado  TEUS OLHOS NOS ACONTECIMENTOS \\nr \\n \\nMinas G...   \n",
       "5          Lixo  HOME › MULTIMIDIA › PODCASTS › Teatro Municipa...   \n",
       "\n",
       "   tamanho_texto  \n",
       "0            929  \n",
       "2           4435  \n",
       "3           6751  \n",
       "4           3359  \n",
       "5           9831  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [compartilhar, facebook, tweet, programa, cami...\n",
       "2    [eduardo, anizellifolhapress, além, postos, re...\n",
       "3    [cerca, 300, moradores, comerciantes, região, ...\n",
       "4    [olhos, acontecimentos, r, minas, gerais, aéci...\n",
       "5    [home, ›, multimidia, ›, podcasts, ›, teatro, ...\n",
       "Name: Conteúdo, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vector = df['Conteúdo'].head(5).apply(text_process)\n",
    "df_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Vetorização **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteudo_vector = CountVectorizer(analyzer=text_process).fit(df['Conteúdo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteudo_vector = conteudo_vector.transform(df['Conteúdo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf_transformer = TfidfTransformer().fit(conteudo_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tfidf_transformer.idf_[conteudo_vector.vocabulary_['fazer']])\n",
    "#print(tfidf_transformer.idf_[conteudo_vector.vocabulary_['lixo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "#print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#model = MultinomialNB().fit(messages_tfidf, df['status'])\n",
    "model = MultinomialNB().fit(conteudo_vector, df['status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('predicted:', model.predict(tfidf4)[0])\n",
    "#print('expected:', df.status[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Classificado' 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Classificado' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Classificado' 'Classificado' 'Classificado'\n",
      " 'Próximo às áreas de atuação CCR' 'Lixo' 'Lixo'\n",
      " 'Próximo às áreas de atuação CCR' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Classificado'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Classificado' 'Classificado' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Classificado'\n",
      " 'Próximo às áreas de atuação CCR' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Lixo' 'Classificado' 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Classificado'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Classificado'\n",
      " 'Classificado' 'Classificado' 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Lixo'\n",
      " 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Classificado' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Lixo' 'Classificado' 'Lixo' 'Lixo' 'Lixo' 'Lixo' 'Classificado'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Lixo' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado' 'Classificado' 'Lixo'\n",
      " 'Classificado' 'Lixo' 'Lixo' 'Classificado']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = model.predict(conteudo_vector)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 89 445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(df['Conteúdo'], df['status'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # Tokeniza as mensagens\n",
    "    ('tfidf', TfidfTransformer()),  # Faz a transformação em TF-IDF\n",
    "    ('classifier', LogisticRegression()),  # Define a classe que realizará nossa classificação.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x0000019C802780D0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocesso...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                   Classificado       0.37      0.93      0.53        15\n",
      "                           Lixo       0.98      0.66      0.79        74\n",
      "Próximo às áreas de atuação CCR       0.00      0.00      0.00         0\n",
      "\n",
      "                    avg / total       0.88      0.71      0.75        89\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
